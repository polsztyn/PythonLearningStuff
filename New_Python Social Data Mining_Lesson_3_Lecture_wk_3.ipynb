{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mining Social Data\n",
    "#Lesson 3: Using Social Media APIs\n",
    "\n",
    "This notebook assumes you have already watched Shilad's [presentation on Social Media APIs](https://www.youtube.com/watch?v=Yyo6kq3Ao4U). The presentation provides a high-level overview of methods for incorporating social data into your applications and analyses.  This notebook supplements the presentation by walking through five detailed case studies that connect to Social APIs in Python.\n",
    "\n",
    "After you complete this lesson, you will be able to:\n",
    "\n",
    "* Connect to Social APIs using Python - both in \"native\" Python and using \"wrapper modules.\"\n",
    "* Create Python code to connect to the Wikipedia, Facebook, Twitter, GitHub and Datasift Social APIs.\n",
    "* Recognize and complete typically authorization scenarios for Social APIs.\n",
    "* Understand the capabilities and tradeoffs of social data aggregation such as Gnip and DataSift.\n",
    "* Be familiar with offline and online patterns of incorporationg data into your applications.\n",
    "\n",
    "# 0. Preparation and setup\n",
    "\n",
    "**Time estimate:** 30 minutes. (If you run into problems, please post to the forum!).\n",
    "\n",
    "**Further optional readings:** [PyPI: The Python Package Index](https://pypi.python.org/pypi)\n",
    "\n",
    "In order to complete this lesson, you'll need to create two accounts and install five Python modules\n",
    "\n",
    "* [Sign up or register on Twitter](http://twitter.com) if you don't have an account.\n",
    "* [Register on Datasift](https://datasift.com/auth/register) and sign up for the free trial (this can take a day or so.)\n",
    "\n",
    "You will also need five Python modules that make it easier to connect to social APIs. Four installations should run smoothly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module wikipedia already installed\n",
      "module twitter already installed\n",
      "module oauth2 already installed\n",
      "installing module facebook-sdk\n",
      "Requirement already satisfied: facebook-sdk in c:\\anaconda\\lib\\site-packages\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from facebook-sdk)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->facebook-sdk)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests->facebook-sdk)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->facebook-sdk)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->facebook-sdk)\n",
      "module praw already installed\n"
     ]
    }
   ],
   "source": [
    "def install_module(package_name):\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        print('module ' + package_name + ' already installed')\n",
    "    except ImportError:\n",
    "        print('installing module ' + package_name)\n",
    "        import pip\n",
    "        pip.main(['install', package_name])\n",
    "\n",
    "install_module('wikipedia')\n",
    "install_module('twitter')\n",
    "install_module('oauth2')\n",
    "install_module('facebook-sdk')\n",
    "install_module('praw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifth produced a warning, but still worked for me. If you have issues, please let me know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing module datasift\n",
      "You are using pip version 6.0.8, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "Collecting datasift\n",
      "  Downloading datasift-2.11.0.tar.gz\n",
      "Collecting requests<3.0.0,>=2.8.0 (from datasift)\n",
      "  Downloading requests-2.18.4-py2.py3-none-any.whl (88kB)\n",
      "Collecting autobahn<0.10.0,>=0.9.4 (from datasift)\n",
      "  Downloading autobahn-0.9.6.tar.gz (137kB)\n",
      "    package init file 'twisted\\plugins\\__init__.py' not found (or not a regular file)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six<2.0.0,>=1.6.0 in c:\\anaconda\\lib\\site-packages (from datasift)\n",
      "Collecting twisted<16.0.0,>=14.0.0 (from datasift)\n",
      "  Downloading Twisted-15.5.0-cp27-none-win_amd64.whl (3.1MB)\n",
      "Collecting pyopenssl<0.16.0,>=0.15.1 (from datasift)\n",
      "  Downloading pyOpenSSL-0.15.1-py2.py3-none-any.whl (102kB)\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil<3,>=2.1 in c:\\anaconda\\lib\\site-packages (from datasift)\n",
      "Collecting service-identity>=14.0.0 (from datasift)\n",
      "  Downloading service_identity-17.0.0-py2.py3-none-any.whl\n",
      "Collecting requests-futures>=0.9.5 (from datasift)\n",
      "  Downloading requests-futures-0.9.7.tar.gz\n",
      "Collecting ndg-httpsclient>=0.4.0 (from datasift)\n",
      "  Downloading ndg_httpsclient-0.4.3-py2-none-any.whl\n",
      "Collecting urllib3<1.23,>=1.21.1 (from requests<3.0.0,>=2.8.0->datasift)\n",
      "  Downloading urllib3-1.22-py2.py3-none-any.whl (132kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.8.0->datasift)\n",
      "  Downloading certifi-2017.11.5-py2.py3-none-any.whl (330kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests<3.0.0,>=2.8.0->datasift)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting idna<2.7,>=2.5 (from requests<3.0.0,>=2.8.0->datasift)\n",
      "  Downloading idna-2.6-py2.py3-none-any.whl (56kB)\n",
      "Collecting zope.interface>=3.6.0 (from twisted<16.0.0,>=14.0.0->datasift)\n",
      "  Downloading zope.interface-4.4.3.tar.gz (147kB)\n",
      "Requirement already satisfied (use --upgrade to upgrade): cryptography>=0.7 in c:\\anaconda\\lib\\site-packages\\cryptography-0.8-py2.7-win-amd64.egg (from pyopenssl<0.16.0,>=0.15.1->datasift)\n",
      "Collecting pyasn1-modules (from service-identity>=14.0.0->datasift)\n",
      "  Downloading pyasn1_modules-0.1.5-py2.py3-none-any.whl (60kB)\n",
      "Collecting attrs (from service-identity>=14.0.0->datasift)\n",
      "  Downloading attrs-17.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyasn1 in c:\\anaconda\\lib\\site-packages (from service-identity>=14.0.0->datasift)\n",
      "Requirement already satisfied (use --upgrade to upgrade): futures>=2.1.3 in c:\\anaconda\\lib\\site-packages (from requests-futures>=0.9.5->datasift)\n",
      "Requirement already satisfied (use --upgrade to upgrade): setuptools in c:\\anaconda\\lib\\site-packages\\setuptools-14.3-py2.7.egg (from zope.interface>=3.6.0->twisted<16.0.0,>=14.0.0->datasift)\n",
      "Requirement already satisfied (use --upgrade to upgrade): enum34 in c:\\anaconda\\lib\\site-packages (from cryptography>=0.7->pyopenssl<0.16.0,>=0.15.1->datasift)\n",
      "Requirement already satisfied (use --upgrade to upgrade): cffi>=0.8 in c:\\anaconda\\lib\\site-packages (from cryptography>=0.7->pyopenssl<0.16.0,>=0.15.1->datasift)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pycparser in c:\\anaconda\\lib\\site-packages (from cffi>=0.8->cryptography>=0.7->pyopenssl<0.16.0,>=0.15.1->datasift)\n",
      "Installing collected packages: attrs, pyasn1-modules, zope.interface, idna, chardet, certifi, urllib3, ndg-httpsclient, requests-futures, service-identity, pyopenssl, twisted, autobahn, requests, datasift\n",
      "\n",
      "\n",
      "  Running setup.py install for zope.interface\n",
      "    building 'zope.interface._zope_interface_coptimizations' extension\n",
      "    ********************************************************************************\n",
      "    WARNING:\n",
      "            An optional code optimization (C extension) could not be compiled.\n",
      "            Optimizations for this package will not be available!\n",
      "    ()\n",
      "    Microsoft Visual C++ 9.0 is required (Unable to find vcvarsall.bat). Get it from http://aka.ms/vcpython27\n",
      "    ********************************************************************************\n",
      "    Skipping installation of C:\\Anaconda\\Lib\\site-packages\\zope\\__init__.py (namespace package)\n",
      "    Installing C:\\Anaconda\\Lib\\site-packages\\zope.interface-4.4.3-py2.7-nspkg.pth\n",
      "\n",
      "\n",
      "  Found existing installation: certifi 14.5.14\n",
      "    DEPRECATION: Uninstalling a distutils installed project (certifi) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\n",
      "    Uninstalling certifi-14.5.14:\n",
      "      Successfully uninstalled certifi-14.5.14\n",
      "\n",
      "\n",
      "\n",
      "  Running setup.py install for requests-futures\n",
      "\n",
      "  Found existing installation: pyOpenSSL 0.14\n",
      "    DEPRECATION: Uninstalling a distutils installed project (pyopenssl) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\n",
      "    Uninstalling pyOpenSSL-0.14:\n",
      "      Successfully uninstalled pyOpenSSL-0.14\n",
      "\n",
      "\n",
      "  Running setup.py install for autobahn\n",
      "    package init file 'twisted\\plugins\\__init__.py' not found (or not a regular file)\n",
      "  Found existing installation: requests 2.6.0\n",
      "    DEPRECATION: Uninstalling a distutils installed project (requests) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\n",
      "    Uninstalling requests-2.6.0:\n",
      "      Successfully uninstalled requests-2.6.0\n",
      "\n",
      "  Running setup.py install for datasift\n",
      "Successfully installed attrs-17.3.0 autobahn-0.9.6 certifi-2017.11.5 chardet-3.0.4 datasift-2.11.0 idna-2.6 ndg-httpsclient-0.4.3 pyasn1-modules-0.1.5 pyopenssl-0.15.1 requests-2.18.4 requests-futures-0.9.7 service-identity-17.0.0 twisted-15.5.0 urllib3-1.22 zope.interface-4.4.3\n"
     ]
    }
   ],
   "source": [
    "install_module('datasift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Plain HTTP + JSON (The simplest possible example)\n",
    "\n",
    "**Time estimate:** 30 minutes (excluding questions #1 and #2).\n",
    "\n",
    "**Further optional reading:**\n",
    "\n",
    "* [Python urllib module](https://docs.python.org/2/library/urllib.html)\n",
    "* [Python json module](https://docs.python.org/2/library/json.html)\n",
    "* [GitHub API documentation](https://api.github.com)\n",
    "* [Wikipedia's JSON article](http://en.wikipedia.org/wiki/JSON)\n",
    "\n",
    "We'll start with a simple example and work towards more complex ones. Let's see the recent activity on GitHub. You can actually view this by opening the url https://api.github.com/events in your browser. Go take a look!\n",
    "\n",
    "You can instruct Python to perform this same request as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my raw response is a <type 'str'>: '[{\"id\":\"6849151979\",\"type\":\"PushEvent\",\"actor\":{\"id\":21224191,\"login\":\"FatFreeBeefCake\",\"display_login\":\"FatFreeBeefCake\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/FatFreeBeefCake\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/21224191?\"},\"repo\":{\"id\":101216063,\"name\":\"FatFreeBeefCake/2670UVU\",\"url\":\"https://api.github.com/repos/FatFreeBeefCake/2670UVU\"},\"payload\":{\"push_id\":212'\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# open an http connection to the url and return a file for it\n",
    "url = urllib.urlopen('https://api.github.com/events')\n",
    "\n",
    "# read the http response into a string.\n",
    "response = url.read()\n",
    "print('my raw response is a %s: %s' % (type(response), repr(response[:400])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the data type of the response above is a string. This string looks a lot like a Python literal, but it not a datastructure - just a string. The string is encoded using a specification called [JSON](http://en.wikipedia.org/wiki/JSON) that uses Javascript literal syntax (very close to Python). \n",
    "\n",
    "In the past APIs used a variety of encoding schemes (often based on XML). These days, almost every social API supports JSON.\n",
    "\n",
    "You could write code to *parse* the JSON and turn it from a string into a native python datastructure. However, it's better to use Python's robust [json module](https://docs.python.org/2/library/json.html). The `json.loads` method takes a string encoded using the JSON specification and returns a native python datastructure. We'll pretty print out the result so you can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed response is a <type 'list'>: [{u'actor': {u'avatar_url': u'https://avatars.githubusercontent.com/u/21224191?',\n",
      "             u'display_login': u'FatFreeBeefCake',\n",
      "             u'gravatar_id': u'',\n",
      "             u'id': 21224191,\n",
      "             u'login': u'FatFreeBeefCake',\n",
      "             u'url': u'https://api.github.com/users/FatFreeBeefCake'},\n",
      "  u'created_at': u'2017-11-13T21:02:55Z',\n",
      "  u'id': u'6849151979',\n",
      "  u'payload': {u'before': u'ca6004526ee95236ba2a818b8fc877f44e0ee3af',\n",
      "               u'commits': [{u'author': {u'email': u'stheadman1@hotmail.com',\n",
      "                                         u'name': u'Unknown'},\n",
      "                             u'distinct': True,\n",
      "                             u'message': u'BG music',\n",
      "                             u'sha': u'ee92dc5dbf8846e20cbb66b435500ea0ea88f27e',\n",
      "                             u'url': u'https://api.github.com/repos/FatFreeBeefCake/2670UVU/commits/ee92dc5dbf8846e20cbb66b435500ea0ea88f27e'}],\n",
      "               u'distinct_size': 1,\n",
      "               u'head': u'ee92dc5dbf8846e20cbb...\n"
     ]
    }
   ],
   "source": [
    "# converts the response string into a native python data structure\n",
    "data = json.loads(response)\n",
    "\n",
    "# returns a human-readable string representing the data structure.\n",
    "data_str = pprint.pformat(data)\n",
    "print('parsed response is a %s: %s...' % (type(data), data_str[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're curious about the format of the GitHub API response (typically called the **payload**), you can take a look at the [GitHub API documentation about events](https://developer.github.com/v3/activity/events/). Most public social APIs have excellent documentation.\n",
    "\n",
    "As a shortcut, you can do this in one line using the `json.load` method that directly parses the file-like object returned by `urllib.urlopen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "url = urllib.urlopen('https://api.github.com/events')\n",
    "data = json.load(url)\n",
    "print(len(data))   # number of events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the decoded json is a native Python data structure, so you can directly interact with it like you would any other Python data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'2017-11-13T21:03:03Z', u'WatchEvent', u'anand32138', u'https://api.github.com/repos/rstacruz/cheatsheets')\n",
      "(u'2017-11-13T21:03:03Z', u'WatchEvent', u'sakopov', u'https://api.github.com/repos/sakopov/Dapper.AmbientContext')\n",
      "(u'2017-11-13T21:03:04Z', u'PushEvent', u'rlewis2892', u'https://api.github.com/repos/deepdivedylan/angular5-example')\n",
      "(u'2017-11-13T21:03:03Z', u'PushEvent', u'melonmj', u'https://api.github.com/repos/melonmj/parse_server_bolsa1a')\n",
      "(u'2017-11-13T21:03:03Z', u'PushEvent', u'tiewei', u'https://api.github.com/repos/tiewei/netplugin')\n",
      "(u'2017-11-13T21:03:03Z', u'IssueCommentEvent', u'arq5x', u'https://api.github.com/repos/arq5x/bedtools2')\n",
      "(u'2017-11-13T21:03:03Z', u'PushEvent', u'tmtmtmtm', u'https://api.github.com/repos/everypolitician-scrapers/macedonia-sobranie')\n",
      "(u'2017-11-13T21:03:04Z', u'PushEvent', u'samyk', u'https://api.github.com/repos/samyk/myo-osc')\n",
      "(u'2017-11-13T21:03:03Z', u'IssueCommentEvent', u'mitar', u'https://api.github.com/repos/tozd/docker-nginx-proxy')\n",
      "(u'2017-11-13T21:03:03Z', u'PullRequestReviewCommentEvent', u'iionly', u'https://api.github.com/repos/iionly/elggx_userpoints')\n"
     ]
    }
   ],
   "source": [
    "for record in data[:10]:\n",
    "    print(record['created_at'], record['type'], record['actor']['login'], record['repo']['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using wrapper modules to access public APIs\n",
    "\n",
    "**Time estimate:** 30 minutes, excluding assignment questions.\n",
    "\n",
    "**Supplemental readings:**\n",
    "\n",
    "* [Wikipedia API](http://www.mediawiki.org/wiki/API:Main_page) \n",
    "* [Goldsmith's Python Wikipedia](https://github.com/goldsmith/Wikipedia)\n",
    "\n",
    "The \"native python\" approach works well for the GitHub API because it is simple. However, this approach can become quite complicated for other APIs. For example, consider an API call to fetch the text of a Wikipedia page. Since the Wikipedia API is public, you can also see the API call and response through your browser by opening http://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&rvlimit=1&format=json&titles=Python_%28programming_language%29\n",
    "\n",
    "The native Python code associated with this API call follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('json keys', [u'ns', u'pageid', u'revisions', u'title'])\n",
      "('title', u'Python (programming language)')\n",
      "('num revisions', 1)\n",
      "('rev keys', <type 'dict'>, [u'*', u'contentmodel', u'contentformat'])\n",
      "('wikitext', \"u'{{Infobox programming language\\\\n|name                   = Python\\\\n|logo                   = Python logo and wordmark.svg\\\\n|logo size              = 260px\\\\n|paradigm               = [[multi-paradigm progra'\")\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import json\n",
    "\n",
    "url = urllib.urlopen('http://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&rvlimit=1&format=json&titles=Python_%28programming_language%29')\n",
    "wp_data = json.load(url) \n",
    "python_data = wp_data['query']['pages'].values()[0]\n",
    "print('json keys', python_data.keys())\n",
    "print('title', python_data['title'])\n",
    "print('num revisions', len(python_data['revisions']))\n",
    "python_rev = python_data['revisions'][0]\n",
    "print('rev keys', type(python_rev), python_rev.keys())\n",
    "wikitext = python_rev['*']\n",
    "print('wikitext', repr(wikitext[:200]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of work to get one Wikipedia page! As it turns out, other parts of the [Wikipedia API](http://www.mediawiki.org/wiki/API:Main_page) are even more obtuse.\n",
    "\n",
    "Luckily, other Python programmers have created Python modules that hide this complexity. A google search for \"Python Wikipedia API Library\" directs you to a [List of Wikipedia Python client wrapper](http://www.mediawiki.org/wiki/API:Client_code#Python). \n",
    "\n",
    "When looking for a wrapper module, you'll often find many choices. One method for choosing a good client wrapper I find effective is to head to the module's GitHub repo (virtually all wrapper modules are hosted on GitHub) and choose the one that a) can be installed using pip, b) seems simple to use and c) is popular, as measured by number of GitHub stars in the upper right. \n",
    "\n",
    "For example, for the Wikipedia API [Goldsmith's Python Wikipedia](https://github.com/goldsmith/Wikipedia) wrapper module fits the first two criteria and has been starred by 757 users. You would typically install the module from the command line using pip:\n",
    "\n",
    "    $ pip install wikipedia\n",
    "    \n",
    "However, I already asked you to install it earlier by running the `install_module` function I wrote. You can verify that it is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module wikipedia already installed\n"
     ]
    }
   ],
   "source": [
    "install_module('wikipedia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have installed the wikipedia module, you can call `wikipedia.page()`, which:\n",
    "\n",
    "1. Constructs an HTTP request to the Wikipedia API, as we did above.\n",
    "2. Parses the HTTP response, which is JSON, into a native python datastructure.\n",
    "3. Returns a Wikipedia [\"page object\"](https://wikipedia.readthedocs.org/en/latest/code.html#module-wikipedia) with user-friendly attributes such as a list of sections and plain text content.\n",
    "\n",
    "Notice how simple the code that follows looks compared to the earlier \"native Python\" code. In general, you'll find it much easier to use these wrapper modules - particularly for APIs which require authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<WikipediaPage 'Python (programming language)'>, <class 'wikipedia.wikipedia.WikipediaPage'>)\n",
      "('sections', [])\n",
      "('content', u'Python is a widely used high-level programming language for general-purpose programming, created by Guido van Rossum and first released in 1991. An interpreted language, Python has a design philosophy that emphasizes code readability (notably using whitespace indentation to delimit code blocks rather than curly brackets or keywords), and a syntax that allows programmers to express concepts in fewer lines of code than might be used in languages such as C++ or Java. The language provides construct')\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "python_page = wikipedia.page('Python_(programming_language)')\n",
    "print(python_page, type(python_page))\n",
    "print('sections', python_page.sections)\n",
    "print('content', python_page.content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using wrapper libraries to access APIs that require authentication\n",
    "\n",
    "**Time estimate:** 90 minutes, excluding assignments.\n",
    "\n",
    "**Supplemental resources:**\n",
    "\n",
    "* [Using the Twitter API with Python tutorial](http://darkmattersheep.net/2013/09/using-twitter-api-with-python/).\n",
    "* Ryan Boyd's overview of OAuth 2.0: https://www.youtube.com/watch?v=YLHyeSuBspI. It's long, but very clear.\n",
    "* [Twitter Developer Site](https://dev.twitter.com/).\n",
    "* [Twitter application-only authentication](https://dev.twitter.com/docs/auth/application-only-auth).\n",
    "\n",
    "GitHub, Reddit and Wikipedia's support for public API access is rare. Most APIs require you to authenticate yourself (prove who you are), typically using a schema called OAuth2. Every API is different (despite all being OAuth2).  \n",
    "\n",
    "In general, you'll follow three steps to retrieve data using OAuth 2.0.\n",
    "\n",
    "**Step A: Register for the service and retrieve your access tokens to it.**\n",
    "\n",
    "1. You will create a user account with the service (Facebook, Twitter, Foursquare, etc).\n",
    "2. You will request \"secret\" access tokens for your account. Most major social APIs provide a web interface for doing so. For many services, you'll receive several different secret different tokens.\n",
    "\n",
    "** Part B: Install a Python API wrapper module.**\n",
    "\n",
    "1. You will install a Python API wrapper module associated with the service. \n",
    "2. You often have several choices for these. Since almost all of these are hosted on GitHub, a useful heuristic proxy for usefulness is the number of stars the project has.\n",
    "\n",
    "**Part C: Develop your Python program.**\n",
    "\n",
    "4. You will provide your access tokens to the Python library to connect to the service.\n",
    "5. Very often, the wrapper module will closely follow the Social Media API, so you'll often need to reference both the Python wrapper's documentation and the social media API documentation.\n",
    "\n",
    "We'll walk through this procedure for both Facebook and Twitter. \n",
    "\n",
    "### 3.1. Accessing Twitter Data\n",
    "\n",
    "**Part A: Create your app and retrieve its access tokens.**\n",
    "\n",
    "1. Create or login to your [Twitter account](http://twitter.com).\n",
    "2. Login to the [Twitter Developer Site](https://dev.twitter.com/) with the same account.\n",
    "3. Visit the [Manage your apps](https://apps.twitter.com/) page.\n",
    "4. Click \"Create new app\".\n",
    "5. Create a name, description and website. The name must be unique. The website can be a placeholder for now. You can leave the callback blank.\n",
    "6. Select \"I agree\" and click \"Create application.\"\n",
    "7. Click the \"API Keys\" tab and click \"Create my access token.\"\n",
    "8. Using information on this page, create a dictionary called config as described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace the contents of this dictionary with your access information.\n",
    "#\n",
    "twitter_config = {\n",
    "        # These two values appear as \"API key\" and \"API secret\" under the \"Application Settings\" section\n",
    "        'API_KEY' :  '',           \n",
    "        'API_SECRET' :  '',\n",
    "        \n",
    "        # These two values appear as \"Access token\" and \"Access token secret\" under the \"Your access token\" section\n",
    "        'ACCESS_TOKEN' :  '',\n",
    "        'ACCESS_SECRET' :  '',\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B: Install the Twitter library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module twitter already installed\n",
      "module oauth2 already installed\n"
     ]
    }
   ],
   "source": [
    "install_module('twitter')\n",
    "install_module('oauth2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C: Python hacking! **\n",
    "\n",
    "First, you must authenticate your Twitter client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twitter import OAuth\n",
    "\n",
    "oauth = OAuth(\n",
    "            twitter_config['ACCESS_TOKEN'],\n",
    "            twitter_config['ACCESS_SECRET'],\n",
    "            twitter_config['API_KEY'],\n",
    "            twitter_config['API_SECRET'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you authenticate the Twitter client, you can use the module to call API methods. you begin by creating a twitter object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twitter import Twitter\n",
    "t = Twitter(auth=oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twitter library essentially mirrors the Twitter API. For example, consider the [search/tweets API call](https://dev.twitter.com/docs/api/1.1/get/search/tweets). We would call and pass it named parameters that correspond to the API documentation. For example, this API call requires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'search_metadata': {u'completed_in': 0.034,\n",
      "                      u'count': 1,\n",
      "                      u'max_id': 930179563639975936L,\n",
      "                      u'max_id_str': u'930179563639975936',\n",
      "                      u'next_results': u'?max_id=930179563639975935&q=trump&lang=es&count=1&include_entities=1',\n",
      "                      u'query': u'trump',\n",
      "                      u'refresh_url': u'?since_id=930179563639975936&q=trump&lang=es&include_entities=1',\n",
      "                      u'since_id': 0,\n",
      "                      u'since_id_str': u'0'},\n",
      " u'statuses': [{u'contributors': None,\n",
      "                u'coordinates': None,\n",
      "                u'created_at': u'Mon Nov 13 21:04:24 +0000 2017',\n",
      "                u'entities': {u'hashtags': [],\n",
      "                              u'media': [{u'display_url': u'pic.twitter.com/qKrt6lbYIK',\n",
      "                                          u'expanded_url': u'https://twitter.com/elpoliticonews/status/930177452956987392/photo/1',\n",
      "                                          u'id': 930166605094506497L,\n",
      "                                          u'id_str': u'930166605094506497',\n",
      "                                          u'indices': [95, 118],\n",
      "                                          u'media_url': u'http://pbs.twimg.com/media/DOidmV6W0AE7D7_.jpg',\n",
      "                                          u'media_url_https': u'https://pbs.twimg.com/media/DOidmV6W0AE7D7_.jpg',\n",
      "                                          u'sizes': {u'large': {u'h': 800,\n",
      "                                                                u'resize': u'fit',\n",
      "                                                                u'w': 1200},\n",
      "                                                     u'medium': {u'h': 800,\n",
      "                                                                 u'resize': u'fit',\n",
      "                                                                 u'w': 1200},\n",
      "                                                     u'small': {u'h': 453,\n",
      "                                                                u'resize': u'fit',\n",
      "                                                                u'w': 680},\n",
      "                                                     u'thumb': {u'h': 150,\n",
      "                                                                u'resize': u'crop',\n",
      "                                                                u'w': 150}},\n",
      "                                          u'source_status_id': 930177452956987392L,\n",
      "                                          u'source_status_id_str': u'930177452956987392',\n",
      "                                          u'source_user_id': 88537980,\n",
      "                                          u'source_user_id_str': u'88537980',\n",
      "                                          u'type': u'photo',\n",
      "                                          u'url': u'https://t.co/qKrt6lbYIK'}],\n",
      "                              u'symbols': [],\n",
      "                              u'urls': [{u'display_url': u'goo.gl/E3Fv2w',\n",
      "                                         u'expanded_url': u'http://goo.gl/E3Fv2w',\n",
      "                                         u'indices': [71, 94],\n",
      "                                         u'url': u'https://t.co/lDCnekPmpo'}],\n",
      "                              u'user_mentions': []},\n",
      "                u'extended_entities': {u'media': [{u'display_url': u'pic.twitter.com/qKrt6lbYIK',\n",
      "                                                   u'expanded_url': u'https://twitter.com/elpoliticonews/status/930177452956987392/photo/1',\n",
      "                                                   u'id': 930166605094506497L,\n",
      "                                                   u'id_str': u'930166605094506497',\n",
      "                                                   u'indices': [95, 118],\n",
      "                                                   u'media_url': u'http://pbs.twimg.com/media/DOidmV6W0AE7D7_.jpg',\n",
      "                                                   u'media_url_https': u'https://pbs.twimg.com/media/DOidmV6W0AE7D7_.jpg',\n",
      "                                                   u'sizes': {u'large': {u'h': 800,\n",
      "                                                                         u'resize': u'fit',\n",
      "                                                                         u'w': 1200},\n",
      "                                                              u'medium': {u'h': 800,\n",
      "                                                                          u'resize': u'fit',\n",
      "                                                                          u'w': 1200},\n",
      "                                                              u'small': {u'h': 453,\n",
      "                                                                         u'resize': u'fit',\n",
      "                                                                         u'w': 680},\n",
      "                                                              u'thumb': {u'h': 150,\n",
      "                                                                         u'resize': u'crop',\n",
      "                                                                         u'w': 150}},\n",
      "                                                   u'source_status_id': 930177452956987392L,\n",
      "                                                   u'source_status_id_str': u'930177452956987392',\n",
      "                                                   u'source_user_id': 88537980,\n",
      "                                                   u'source_user_id_str': u'88537980',\n",
      "                                                   u'type': u'photo',\n",
      "                                                   u'url': u'https://t.co/qKrt6lbYIK'}]},\n",
      "                u'favorite_count': 0,\n",
      "                u'favorited': False,\n",
      "                u'geo': None,\n",
      "                u'id': 930179563639975936L,\n",
      "                u'id_str': u'930179563639975936',\n",
      "                u'in_reply_to_screen_name': None,\n",
      "                u'in_reply_to_status_id': None,\n",
      "                u'in_reply_to_status_id_str': None,\n",
      "                u'in_reply_to_user_id': None,\n",
      "                u'in_reply_to_user_id_str': None,\n",
      "                u'is_quote_status': False,\n",
      "                u'lang': u'es',\n",
      "                u'metadata': {u'iso_language_code': u'es',\n",
      "                              u'result_type': u'recent'},\n",
      "                u'place': None,\n",
      "                u'possibly_sensitive': False,\n",
      "                u'retweet_count': 0,\n",
      "                u'retweeted': False,\n",
      "                u'source': u'<a href=\"https://ifttt.com\" rel=\"nofollow\">IFTTT</a>',\n",
      "                u'text': u'\\xbfPidiendo cacao? Nicol\\xe1s reconoce que sue\\xf1a con visitar la Casa Blanca\\nhttps://t.co/lDCnekPmpo https://t.co/qKrt6lbYIK',\n",
      "                u'truncated': False,\n",
      "                u'user': {u'contributors_enabled': False,\n",
      "                          u'created_at': u'Sun Dec 09 17:37:19 +0000 2012',\n",
      "                          u'default_profile': False,\n",
      "                          u'default_profile_image': False,\n",
      "                          u'description': u'Las mejores noticias de Miami para todos los latinos en USA',\n",
      "                          u'entities': {u'description': {u'urls': []},\n",
      "                                        u'url': {u'urls': [{u'display_url': u'facebook.com/noticiasmiami/',\n",
      "                                                            u'expanded_url': u'https://www.facebook.com/noticiasmiami/',\n",
      "                                                            u'indices': [0,\n",
      "                                                                         23],\n",
      "                                                            u'url': u'https://t.co/6WUQceouO4'}]}},\n",
      "                          u'favourites_count': 7254,\n",
      "                          u'follow_request_sent': False,\n",
      "                          u'followers_count': 68128,\n",
      "                          u'following': False,\n",
      "                          u'friends_count': 21,\n",
      "                          u'geo_enabled': False,\n",
      "                          u'has_extended_profile': False,\n",
      "                          u'id': 999771745,\n",
      "                          u'id_str': u'999771745',\n",
      "                          u'is_translation_enabled': False,\n",
      "                          u'is_translator': False,\n",
      "                          u'lang': u'es',\n",
      "                          u'listed_count': 713,\n",
      "                          u'location': u'Miami, FL',\n",
      "                          u'name': u'Noticias Miami',\n",
      "                          u'notifications': False,\n",
      "                          u'profile_background_color': u'C0DEED',\n",
      "                          u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/434045762507259904/zJbkwZzx.jpeg',\n",
      "                          u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/434045762507259904/zJbkwZzx.jpeg',\n",
      "                          u'profile_background_tile': True,\n",
      "                          u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/999771745/1472356238',\n",
      "                          u'profile_image_url': u'http://pbs.twimg.com/profile_images/817061366821425152/SaJW-KuU_normal.jpg',\n",
      "                          u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/817061366821425152/SaJW-KuU_normal.jpg',\n",
      "                          u'profile_link_color': u'34495E',\n",
      "                          u'profile_sidebar_border_color': u'FFFFFF',\n",
      "                          u'profile_sidebar_fill_color': u'DDEEF6',\n",
      "                          u'profile_text_color': u'333333',\n",
      "                          u'profile_use_background_image': True,\n",
      "                          u'protected': False,\n",
      "                          u'screen_name': u'noticiasmiami',\n",
      "                          u'statuses_count': 893466,\n",
      "                          u'time_zone': u'Atlantic Time (Canada)',\n",
      "                          u'translator_type': u'none',\n",
      "                          u'url': u'https://t.co/6WUQceouO4',\n",
      "                          u'utc_offset': -14400,\n",
      "                          u'verified': False}}]}\n",
      "('!!!!! user,text,tstamp', u'Noticias Miami', u'\\xbfPidiendo cacao? Nicol\\xe1s reconoce que sue\\xf1a con visitar la Casa Blanca\\nhttps://t.co/lDCnekPmpo https://t.co/qKrt6lbYIK', u'Mon Nov 13 21:04:24 +0000 2017')\n",
      "('!!!!!crimea user,text,tstamp', u'Sonoma County News', u\"Trump's holding up on long Asia trip and wants you to know it https://t.co/hbzR2sFHY5\", u'Mon Nov 13 21:01:10 +0000 2017')\n"
     ]
    }
   ],
   "source": [
    "from twitter import OAuth\n",
    "\n",
    "oauth = OAuth(\n",
    "            twitter_config['ACCESS_TOKEN'],\n",
    "            twitter_config['ACCESS_SECRET'],\n",
    "            twitter_config['API_KEY'],\n",
    "            twitter_config['API_SECRET'],\n",
    "        )\n",
    "\n",
    "import pprint\n",
    "from twitter import Twitter\n",
    "t = Twitter(auth=oauth)\n",
    "\n",
    "# The format of the parameters are detailed at https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "# Get the first result of a query for 'Obama' in Spanish\n",
    "tweets = t.search.tweets(q='trump', lang='es', count=1)\n",
    "\n",
    "# The structure of a response is detailed at the same webpage.\n",
    "trump_tweet_str = pprint.pformat(tweets)\n",
    "print trump_tweet_str\n",
    "\n",
    "first  = tweets['statuses'][0]\n",
    "user = first['user']['name']\n",
    "text = first['text']\n",
    "tstamp = first['created_at']\n",
    "print(\"!!!!! user,text,tstamp\",user, text, tstamp)\n",
    "\n",
    "# Get the first tweet within Crimea\n",
    "# lat,long,radius  50 miles around the center of Crimea\n",
    "crimea = '45.3,34.4,100mi'\n",
    "tweets = t.search.tweets(q='is', geocode=crimea)\n",
    "\n",
    "first  = tweets['statuses'][0]\n",
    "user = first['user']['name']\n",
    "text = first['text']\n",
    "tstamp = first['created_at']\n",
    "print(\"!!!!!crimea user,text,tstamp\",user, text, tstamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stream a realtime sample of tweets associated with a particular query. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TJEstes1210 Mon Nov 13 21:04:55 +0000 2017 RT @AnnaApp91838450: https://t.co/nEB7TVpN8s\n",
      "Where's ALL THE Republicans on this info ? #PERSIST JUSTICE FOR AMERICA LAW AND ORDER #MAGA… \n",
      "Ashley_9345 Mon Nov 13 21:04:55 +0000 2017 RT @keithboykin: If Obama had spent 5 years lying about George Bush’s birth certificate, had 5 kids from 3 women, and his third wife… \n",
      "crabbydick Mon Nov 13 21:04:56 +0000 2017 RT @DailyCaller: Trump’s New Labor Prosecutor Could Undo Obama-Era Union Wins In A Big Way https://t.co/5Jsjsan03w https://t.co/Wmc9Lul62W\n",
      "xfranman Mon Nov 13 21:04:56 +0000 2017 @WhiteHouse Really pulling out the stops for our President. When Obama went to these things they couldn't manage a… https://t.co/eG001hbLGd\n",
      "angel_leXO Mon Nov 13 21:04:56 +0000 2017 RT @keithboykin: If Obama had spent 5 years lying about George Bush’s birth certificate, had 5 kids from 3 women, and his third wife… \n",
      "JohnABarclayIV Mon Nov 13 21:04:56 +0000 2017 RT @The_Trump_Train: President Trump underestimated Barack Obama’s ability to corrupt every single federal agency at the highest level. Tim…\n",
      "Squirrely24 Mon Nov 13 21:04:56 +0000 2017 RT @PhilMcCrackin44: Of the two women depicted below, one absolutely loves the United States of America.....The other not so much.\n",
      "\n",
      "💥Any… \n",
      "EricGomezAsia Mon Nov 13 21:04:57 +0000 2017 I didn't closely follow the White House website during the Obama admin. Is it odd for the press secretary to post a… https://t.co/fHgH9PB772\n",
      "BlaisBlais5 Mon Nov 13 21:04:57 +0000 2017 RT @keithboykin: Trump spent 15 years accusing the Central Park Five of rape even after they were exonerated and 5 years lying about… \n",
      "WakeUpCanada1 Mon Nov 13 21:04:57 +0000 2017 #Obama gave 'Medals of Freedom' to his #Hollywood groupies......believe that.... https://t.co/jRixb19xqe\n",
      "powerglobalus Mon Nov 13 21:04:57 +0000 2017 @JustSayn2018 https://t.co/OeIKTjqDTP\n",
      "Alexinthecenter Mon Nov 13 21:04:57 +0000 2017 RT @KT_So_It_Goes: THE KEURIG-SOROS-CLINTON-OBAMA CONSPIRACY TRYING TO BRING DOWN AN ALABAMA PATRIOT, GERALDO AND SHERIFF CLARKE JOIN ME ON…\n"
     ]
    }
   ],
   "source": [
    "from twitter import TwitterStream\n",
    " \n",
    "ts = TwitterStream(auth = oauth)\n",
    "openstream = ts.statuses.filter(track='obama')\n",
    "for (i, item) in enumerate(openstream):\n",
    "    print item['user']['screen_name'], item['created_at'], item['text']\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.2. Accessing Facebook Data\n",
    "We perform a similar process for Facebook. I presume you already have a Facebook account. \n",
    "\n",
    "1. Log into your Facebook account.\n",
    "2. Go to the Facebook graph explorer: https://developers.facebook.com/tools/explorer/\n",
    "3. Request a new access token, and record it for use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install_module('facebook-sdk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the [Python Facebook SDK](https://github.com/pythonforfacebook/facebook-sdk) module to print out information about you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "GraphAPIError",
     "evalue": "Invalid OAuth access token.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGraphAPIError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-39d43d6abd12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mACCESS_TOKEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'10153606741636730'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfacebook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mACCESS_TOKEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"me\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\facebook\\__init__.pyc\u001b[0m in \u001b[0;36mget_object\u001b[1;34m(self, id, **args)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;34m\"\"\"Fetches the given object from the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\facebook\\__init__.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, path, args, post_args, files, method)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mGraphAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mGraphAPIError\u001b[0m: Invalid OAuth access token."
     ]
    }
   ],
   "source": [
    "import facebook\n",
    "#{\n",
    "#  \"id\": \"\",\n",
    "#  \"name\": \"Paul Olsztyn\"\n",
    "#}\n",
    "\n",
    "# replace with access token from https://developers.facebook.com/tools/explorer/\n",
    "ACCESS_TOKEN = ''\n",
    "graph = facebook.GraphAPI(ACCESS_TOKEN)\n",
    "print(graph.get_object(\"me\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Accessing data through Social Media Syndication Services.\n",
    "\n",
    "**Time estimate:** 90 minutes (excluding assignment questions).\n",
    "\n",
    "Interacting with social media APIs directly or through a Python wrapper module provides a cost-effective and flexible way to download data. However, it comes with limitations. It takes time to learn and write code for each API. In addition, some data is not available through APIs. For example, Twitter does not include tweets more than two weeks old in API search results.\n",
    "\n",
    "Social Media Syndication services overcome these limitations in exchange for a significant licensing fee. Two syndication services dominate the market: [Gnip](http://gnip.com/) and [DataSift](http://datasift.com). Since Gnip pricing starts at $500, we will experiment with DataSift using a two-week trial license.\n",
    "\n",
    "**Step A: Sign up for a DataSift trial.**\n",
    "\n",
    "Head to https://datasift.com/auth/register and sign up for the trial registration. It may take a day to approve your trial registration.\n",
    "\n",
    "Once you've activated your account, visit your [DataSift dashboard](http://datasift.com/dashboard). You'll notice that you have $10 of trial credits to spend. As long as you're careful with your feeds, this should be plenty for our purposes.\n",
    "\n",
    "Spend some time browsing the available [DataSift data sources](https://datasift.com/source). Since we want to conserve money, we'll focus on the relatively inexpensive Tumblr datasource (Your $10 free credits will easily cover all class activity). Enable the [Tumblr datasource](https://app.datasift.com/source/53/tumblr), which contains all Tumblr interactions. \n",
    "\n",
    "Install https://github.com/msmathers/datasift-python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step B: Install the datasift module**\n",
    "\n",
    "Next, you should install the [official Datasift Python wrapper module](https://github.com/datasift/datasift-python).\n",
    "\n",
    "I had to run the installation command below twice. The command failed to install the https secure web protocol on my computer, so you'll see that I disable https below by passing `ssl=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module datasift already installed\n"
     ]
    }
   ],
   "source": [
    "install_module('datasift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step C: Write Python code against DataSift**\n",
    "\n",
    "After you've finished installing the module, you can experiment with your new data feed. \n",
    "\n",
    "Note that **THIS CODE WILL NOT WORK IN IPYTHON NOTEBOOK**. The multiprocessing design of datasift is incompatible with notebook's design. Instead, you should run the following code directly in ipython (from the command line or as a script).\n",
    "\n",
    "Note the csdl query that follows looks for all public facebook posts with \"good\" in the text. When I ran this query, I found a post about every ten seconds or so.\n",
    "\n",
    "```\n",
    "tumblr.body contains \"python\" OR tumblr.tags contains \"python\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from datasift import Client\n",
    "    \n",
    "    # Fill in account credentials from https://datasift.com/settings\n",
    "    client = Client( \"shilad\",  \"XXXX \", ssl=False)\n",
    "    \n",
    "    @client.on_delete\n",
    "    def on_delete(interaction):\n",
    "        pass\n",
    "    \n",
    "    @client.on_open\n",
    "    def on_open():\n",
    "        print( 'Streaming ready, can start subscribing')\n",
    "        csdl = 'tumblr.body contains \"python\" OR tumblr.tags contains \"python\"'\n",
    "        stream = client.compile(csdl)['hash']\n",
    "    \n",
    "        @client.subscribe(stream)\n",
    "        def subscribe_to_hash(msg):\n",
    "            print( msg)\n",
    "    \n",
    "    @client.on_ds_message\n",
    "    def on_ds_message(msg):\n",
    "        print( 'DS Message %s' % msg)\n",
    "    \n",
    "    #must start stream subscriber\n",
    "    client.start_stream_subscriber()\n",
    "   \n",
    "### An aside: Python's decorators.\n",
    "\n",
    "You'll notice the rather strange structure of the code above. After creating the client object and saving it in the `client` variable we see a bunch of lines starting with `@` above functions.These `@` lines mark functions as **decorators.** In this clase, because the start with `@client`, they alter (or decorate) the functionality of the client variable. Jeff Knupp has authored a [fantastic tutorial on decorators](https://www.jeffknupp.com/blog/2013/11/29/improve-your-python-decorators-explained/).\n",
    "\n",
    "For instance, the `@client.on_ds_message` annotation tells Python that the function that follows it should alter the client variable's `on_ds_message` function:\n",
    "\n",
    "    @client.on_ds_message\n",
    "        def on_ds_message(msg):\n",
    "            print( 'DS Message %s' % msg)\n",
    "            \n",
    "This code is used to create custom **handlers** for different types of events that come through the stream. You'll notice the `on_open` decorator locates substantially more complex than the other decorators. It is triggered after the client connects to datasift's webservers, and it subscribes to the facebook query feed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
