{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Social data mining, Shilad Sen\n",
    "#Assignment 1: 35 points\n",
    "\n",
    "##Question 1: Modeling tweets\n",
    "\n",
    "<style type=\"text/css\">\n",
    "iframe.twitter-tweet {\n",
    "width:800px !important;\n",
    "}\n",
    "</style>\n",
    "\n",
    "**Background:** In this question you will practice creating and navigating data structures that represent real world social media. At the end of this question you should be more comfortable translating social media into Python data structures. \n",
    "\n",
    "**Completion time:** This question should take you approximately one hour. \n",
    "\n",
    "**Point value:** Ungraded, immediate feedback.\n",
    "\n",
    "**Part A.** Write Python code that declares a variable called `tweets` and fills it with three tweets.\n",
    "\n",
    " * The top level `tweets` data structure should be organized by username. Given a username, we should be able to easily retrieve the user's tweets.\n",
    " * Each tweet should contain three attributes: an author's username, the text of the tweet, and the usernames that have favorited the tweet. **You only need to include a few usernames that favorite each tweet.**\n",
    " * You may find it easier to fill the tweets variable in several steps, instead of defining it all at once.\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" lang=\"en\" width=\"100%\"><p>News! Based on <a href=\"https://twitter.com/NateSilver538\">@NateSilver538</a>&#39;s calculations, there&#39;s a 90.617854% chance weâ€™re relaunching FiveThirtyEight on March 17.</p>&mdash; FiveThirtyEight (@FiveThirtyEight) <a href=\"https://twitter.com/FiveThirtyEight/statuses/442372247379247105\">March 8, 2014</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" lang=\"en\"><p>The Fox knows many little things; The hedgehog knows one big thing. <a href=\"http://t.co/GWSmHaatPD\">http://t.co/GWSmHaatPD</a> <a href=\"http://t.co/4s6rNpp5zi\">http://t.co/4s6rNpp5zi</a></p>&mdash; FiveThirtyEight (@FiveThirtyEight) <a href=\"https://twitter.com/FiveThirtyEight/statuses/442384984540999680\">March 8, 2014</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" lang=\"en\"><p>What scientific idea is ready for retirement? It is the standard deviation! (according to Nassim Taleb) <a href=\"http://t.co/0xvKRa1UNb\">http://t.co/0xvKRa1UNb</a></p>&mdash; Jure Leskovec (@jure) <a href=\"https://twitter.com/jure/statuses/423611752417202176\">January 16, 2014</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "\n",
    "**Part B.** Write Python code to count and print out the total number of times each users' tweets have been favorited. As of March 9, 2014, this would be:\n",
    "\n",
    "<pre>\n",
    "    ('number of favorites for tweeter', 'FiveThirtyEight', 273)\n",
    "    ('number of favorites for tweeter', 'Jure Leskovec', 13)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = {}\n",
    "tweets[FiveThirtyEight ]=['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Finding the highest rated movies.\n",
    "\n",
    "**Background:** In this question you will practice dealing with noisy social data that has widely varying sample sizes. Upon completing this assignment, you will 1) Know how to estimate simple values like the mean in a way that accounts for small sample sizes. 2) Write programs that analyze data in a streaming structure. 3) Use dictionaries (and more specifically Python's defaultdict) to create an accumulator for different groups of samples. \n",
    "\n",
    "**Completion time:** This question should take you about two hours.\n",
    "\n",
    "**Point value:** 10 points\n",
    "\n",
    "**Instructions:** Write  a Python program that calculates the robust means for all movies in the MovieLens 10M dataset. Note: your program **must not** store all the ratings for each movie in memory. \n",
    "\n",
    " 1. Your program should create an accumulator variable called `sums` that keeps track of the sum of ratings for each movies.\n",
    " 1. Your program should create an accumulator variable called `counts` that keeps track of the count of ratings for each movie.\n",
    " 1. Your program should stream through each movie rating.\n",
    " 1. For each rating, your program should update the two accumulator data structures.\n",
    " 1. Your program should create a dictionary called `robust_means` whose keys will be movie ids and values will be robust means.\n",
    " 1. Your program should fill the `robust_means` dictionary using data in the `sums` and `counts` accumulators.\n",
    " 1. Your program should print the movie id, number of ratings, real mean, and robust mean for the 20 movies with highest and lowest robust means. Hint: You'll need to sort the robust_means dictionary by value. See [this Stackoverflow post](http://stackoverflow.com/questions/613183/python-sort-a-dictionary-by-value/3177911#3177911) for help.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: If you liked \"Star Wars,\" you'll like ?\n",
    "\n",
    "**Introduction:** For this question, you will generalize the code above to simultaneously calculate the correlation with Star Wars and every other movie. Upon completion of this homework, 1) You'll know how to build an associative recommender system, and 2) You'll have gained experience in using nested accumulator data structures for streaming datasets.\n",
    "\n",
    "**Completion time:** This question should require 3-5 hours.\n",
    "\n",
    "**Point value:** 15 points\n",
    "\n",
    "**Generalizing the correlation algorithm:**\n",
    "Recall the structure of our cosimilarity code above. \n",
    "To calculate the correlation between Star Wars and Finding Nemo, we needed two lists: X and Y.\n",
    "Each list contained one entry for every user who rated both movies.\n",
    "For example, X[2] contains the rating for Toy Story for the third user who rated both movies, and Y[2] contains the same user's rating for Finding Nemo.\n",
    "\n",
    "To generalize this program to simultaneously calculate the correlation between ratings for Star Wars and every other movie, we need to simultaneously calculate the X and Y lists for every other movie. We'll use one data structure that calculates every movie's X called `every_X` and a similar datastructure called `every_Y`. These will be nested datastructures? What will they look like?\n",
    "\n",
    "Note that although `every_X` always contains user ratings for Star Wars, it will contain a different list of ratings for each candidate movie (i.e. the lists stored by `every_X` will be different for Lion King and Finding Nemo).\n",
    "This is because each list in `every_X` only includes ratings for users who rated both Star Wars and the candidate movie.\n",
    "\n",
    "**Helper function for reading movie titles:** Your program will need to look up a movie's title given its id. The read_titles method below returns a dictionary whose keys are movie ids (ints) and values are titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_titles(path):\n",
    "    \"\"\"\n",
    "        Read in the movie ids and their associated titles.\n",
    "        Returns a hashtable containing the association.\n",
    "        Note that the ids are ints.  \n",
    "    \"\"\"\n",
    "    titles = {}\n",
    "    for line in open(path, 'r'):\n",
    "        tokens = line.split('::')\n",
    "        if len(tokens) >= 2:\n",
    "            (id, title) = tokens[:2]\n",
    "            titles[int(id)] = title\n",
    "    return titles\n",
    "\n",
    "# replace this with the full path to the movies.dat on your computer\n",
    "path_movies = '/Users/shilad/Downloads/ml-10M100K/movies.dat' \n",
    "\n",
    "titles = read_titles(path_movies)\n",
    "for i in range(1, 10):\n",
    "    print(i, titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    " 1. Create two data structures to hold rating lists for every movie: `every_X` and `every_Y`. \n",
    "    Carefully plan the contents of these data structures and describe them in your source code.\n",
    " 1. While reading in users via the `read_users()` method, skip all users who have not rated Star Wars (movie id 260).\n",
    " 1. For each user who has rated Star Wars, update `every_X` and `every_Y` for each movie they have rated.\n",
    " 1. After you have finished processing all users, create a dictionary called `every_correlation`.\n",
    " 1. Fill `every_correlation` with the correlations for every movie with at least 1000 ratings using the data in `every_X` and `every_Y`.\n",
    " 1. Print the 20 movies along with highest correlations. You'll need to sort the dictionary by values, as you did in Assignment 1.2.  The first two movies you should see should be obvious choices for the movies most related to Star Wars.  If they aren't, you've done something wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Analyzing time complexity\n",
    "\n",
    "**Introduction:** For this question, you will practice analyzing the time complexity of Python code. Although understanding time complexity well requires a dedicated course, when you finish this question you'll improve your intution about time complexity.\n",
    "\n",
    "**Completion time:** This question should require about 2 hours.\n",
    "\n",
    "**Point value:** 10 points.\n",
    "\n",
    "**Part A:** I've given you three Python functions below: f, g, and h. Each has a different time complexity. If you run the cell below in inotebook, it will report how long it takes to run f, g, and h. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(n):\n",
    "    n += 1\n",
    "    return\n",
    "\n",
    "def g(n):\n",
    "    j = 1\n",
    "    for i in range(n):\n",
    "        j += 1\n",
    "    return\n",
    "\n",
    "def h(n):\n",
    "    j = 1\n",
    "    for i in range(n):\n",
    "        for k in range(n):\n",
    "            j += 1\n",
    "    return\n",
    "\n",
    "n = 1000\n",
    "%time f(n)\n",
    "%time g(n)\n",
    "%time h(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time how long it takes f, g, and h to run as you increase n by factors of 2 (n=1000, 2000, 4000, etc.). Then do the following:\n",
    "\n",
    " 1. Record  (via markdown or comments) how long it takes to run f, g, and h for each value of n.\n",
    " 1. Describe the patterns do you see for each.\n",
    " 1. What time complexities do your observations suggest for f, g, and h?\n",
    " 1. Why does the code in each function generate the time complexities you observed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Repeat the previous procedure from Part 1 for the functions p and q below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p(n):\n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.insert(0, 'foo')     # insert 'foo' to the beginning (the 0'th position)\n",
    "def q(n):\n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append('foo')        # append 'foo' to the end\n",
    "\n",
    "n = 40000\n",
    "%time p(n)\n",
    "%time q(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time how long it takes p and q to run as you increase n by factors of 2 (this time start with n=10000). Then do the following:\n",
    " \n",
    " 1. Record  (via markdown or comments) how long it takes to run p and q for each value of n.\n",
    " 1. Describe the patterns do you see for each.\n",
    " 1. What time complexities do your observations suggest for p and q?\n",
    " 1. Why does the code in each function generate the time complexities you observed? Hint: Python's list uses an array that stores elements in consecutive memory locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Estimate the time complexity of the code you wrote for question 2 in terms of the number of movie ratings n. You do not need to include an analysis of step 7 - only steps 1 through 6. Explain your answer.\n",
    "\n",
    "To help you, consider what actions you perform for each rating. What data structures are used? How fast are the operations you use on those data structures?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Estimate the time complexity of the code you wrote for question 3 in terms of the number of movie ratings n. You do not need to include an analysis of step 6 - only steps 1 through 5. \n",
    "\n",
    "To make your analysis simpler, presume *every* user has rated Star Wars. How would you adjust your analysis to account for the fact that only some people rate Star Wars?\n",
    "\n",
    "Make sure to explain your answer.\n",
    "\n",
    "As a hint, consider what actions you perform for each rating. What data structures are used? How fast are the operations you use on those data structures?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
